"""
Hugging Face Trending æŠ“å–å™¨
æŠ“å–Hugging Faceä¸Šçƒ­é—¨çš„AIæ¨¡å‹
"""

from typing import List
from datetime import datetime
import requests

from ..utils.logger import get_logger
from .base import BaseFetcher, NewsItem


class HuggingFaceFetcher(BaseFetcher):
    """Hugging Face Trending æŠ“å–å™¨"""

    def __init__(self, max_news: int = 5, use_retry: bool = True):
        super().__init__("Hugging Face", "https://huggingface.co", max_news, use_retry=use_retry)

    def fetch(self) -> List[NewsItem]:
        """æŠ“å–Hugging Faceçƒ­é—¨æ¨¡å‹ - æŒ‰æœ€è¿‘æ›´æ–°æ’åº"""
        self.logger.info("å¼€å§‹æŠ“å–Hugging Faceçƒ­é—¨æ¨¡å‹")

        try:
            # ä½¿ç”¨APIè·å–çƒ­é—¨æ¨¡å‹ - æŒ‰ä¸‹è½½é‡æ’åº
            api_url = "https://huggingface.co/api/models"
            params = {
                "limit": 100,  # å¢åŠ å€™é€‰æ•°é‡
                "sort": "downloads",  # æŒ‰ä¸‹è½½é‡æ’åºï¼Œè·å–çƒ­é—¨æ¨¡å‹
                "filter": "pytorch"  # åªè·å–PyTorchæ¨¡å‹
            }

            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }

            response = requests.get(api_url, params=params, headers=headers, timeout=15)

            if response.status_code != 200:
                self.logger.warning(f"Hugging Face APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return []

            models = response.json()
            news_list = []

            for model in models[:self.max_news * 10]:  # å¢åŠ å€™é€‰æ•°é‡
                try:
                    model_id = model.get('id', '')
                    if not model_id:
                        continue

                    # è·å–æ¨¡å‹è¯¦æƒ…
                    model_data = self._get_model_details(model_id)
                    if not model_data:
                        continue

                    # ä»model_dataè·å–ä¸‹è½½é‡å’Œç‚¹èµæ•°
                    downloads = model_data.get('downloads', 0)
                    likes = model_data.get('likes', 0)

                    # è·³è¿‡ä¸‹è½½é‡å¤ªä½çš„æ¨¡å‹ï¼ˆå¯èƒ½æ˜¯æµ‹è¯•/ä¸ªäººæ¨¡å‹ï¼‰
                    if downloads < 100:
                        continue

                    # è·³è¿‡å¤ªè€çš„åŸºç¡€æ¨¡å‹ï¼ˆé™¤éæœ‰å¤§é‡ä¸‹è½½ï¼‰
                    model_name = model_id.lower()
                    skip_models = ['bert', 'gpt2', 'resnet', 'mobilenet', 'efficientnet', 'vit']
                    if any(skip in model_name for skip in skip_models):
                        # å¦‚æœæ˜¯æœ€è¿‘æ›´æ–°çš„ä¿ç•™
                        if downloads < 100000:
                            continue

                    # æ ¼å¼åŒ–ä¸‹è½½é‡
                    if downloads >= 1000000:
                        dl_str = f"{downloads/1000000:.1f}M"
                    elif downloads >= 1000:
                        dl_str = f"{downloads/1000:.1f}K"
                    else:
                        dl_str = str(downloads)

                    # æ ‡é¢˜åªç”¨æ¨¡å‹åç§°ï¼Œç®€æ´æ¸…æ™°
                    title = model_id

                    # åªæ˜¾ç¤ºæœ‰è¶£çš„æè¿°ï¼Œé¿å…å¤ªæŠ€æœ¯åŒ–
                    description = model_data.get('description', '')
                    if description and len(description) < 100:
                        # æ¸…ç†æè¿°ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                        description = description.replace('\n', ' ').replace('\r', '')
                        title += f" - {description}"

                    # æ„å»ºæ‘˜è¦ - ä¸‹è½½é‡æ”¾åœ¨æœ€å‰é¢ï¼Œç”¨äºåœ¨æ¨¡æ¿ä¸­æ˜¾ç¤º
                    summary_parts = [f"ä¸‹è½½: {dl_str}"]
                    if model_data.get('pipeline_tag'):
                        summary_parts.append(f"ä»»åŠ¡: {model_data['pipeline_tag']}")
                    if likes:
                        summary_parts.append(f"ğŸ‘ {likes}")

                    news_list.append(NewsItem(
                        title=title,
                        url=f"https://huggingface.co/{model_id}",
                        source="Hugging Face",
                        region="global",
                        summary=" | ".join(summary_parts) if summary_parts else "",
                        date=datetime.now().strftime('%Y-%m-%d'),
                        news_type="huggingface"
                    ))

                    if len(news_list) >= self.max_news:
                        break

                except Exception as e:
                    self.logger.debug(f"è§£ææ¨¡å‹å¤±è´¥: {e}")
                    continue

            if news_list:
                self.logger.info(f"ä» Hugging Face è·å–åˆ° {len(news_list)} ä¸ªçƒ­é—¨æ¨¡å‹")
            else:
                self.logger.info("Hugging Faceæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ¨¡å‹")

            return news_list

        except Exception as e:
            self.logger.error(f"Hugging FaceæŠ“å–å¤±è´¥: {e}")
            return []

    def _get_model_details(self, model_id: str) -> dict:
        """è·å–æ¨¡å‹è¯¦æƒ…"""
        try:
            url = f"https://huggingface.co/api/models/{model_id}"
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return {}
